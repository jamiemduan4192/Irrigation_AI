{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikeras scikit-learn scikeras tensorflow scikeras"
      ],
      "metadata": {
        "id": "GAYT3mGy4rSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1. Import libraries**\n"
      ],
      "metadata": {
        "id": "zqKh2OLeNTNC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtnDAEQUZvCf"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "# Core\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow / Keras\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2. Connect to google drive or load dataset**\n",
        "There are two options to open up dataset\n",
        "\n",
        "\n",
        "*   Direct load from google drive by mount colab with Google drive using from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "*   Upload from local laptop\n",
        "\n"
      ],
      "metadata": {
        "id": "N2aZjC-cNdZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSc9yF02ZvRC"
      },
      "outputs": [],
      "source": [
        "# //connect to google drive//\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#// uplodaing data into google cola//\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# //Store and show the data//\n",
        "df = pd.read_csv('/content/drive/MyDrive/GEE_irrigation/NLDAS_solar_weather_2023_Tcns.csv') # replace path\n",
        "df # to print the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3. Prepare Data for Modeling**\n",
        "- Selects key predictor variables from the NLDAS dataset:\n",
        "  - `pa` → surface pressure  \n",
        "  - `ppt` → precipitation  \n",
        "  - `swin` → shortwave radiation  \n",
        "  - `ta` → air temperature  \n",
        "- Defines the target variable `y = Tcns` (observed canopy temperature).  \n",
        "- Splits data into training and testing subsets using `train_test_split`:  \n",
        "  - 70% for training,  \n",
        "  - 30% for testing,  \n",
        "  - `random_state=45` ensures reproducibility.  \n"
      ],
      "metadata": {
        "id": "d2RtqpZeZAth"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2jAJjOBZvZh"
      },
      "outputs": [],
      "source": [
        "# defining model independent (X) and dependent (y) values\n",
        "X = df[['pa','ppt','swin','ta']]\n",
        "y = df['Tcns']\n",
        "print (X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 45)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4. Train a Recurrent Neural Network (RNN)**\n",
        "\n",
        "In this step we build and train a **Simple RNN** to predict canopy temperature (`Tcns`) from NLDAS predictors.  \n",
        "\n",
        "- **Define model architecture (`rnn_model`)**  \n",
        "   - `Sequential()` → builds a model where layers are added in sequence.  \n",
        "   - `SimpleRNN(20, input_shape=(4,1), activation='relu')` → recurrent layer with 20 neurons, expecting input shaped as 4 features × 1 timestep.  \n",
        "   - Three `Dense(10, activation='relu')` layers with L2 regularization → prevent overfitting by penalizing large weights.  \n",
        "   - `Dense(1, activation='linear')` → output layer for regression (continuous values).  \n",
        "   - Optimizer = **Adam** with learning rate 0.01.  \n",
        "   - Loss = **MSE (Mean Squared Error)**, Metrics = MSE & MAE.  \n",
        "\n",
        "- **Early stopping (`EarlyStopping`)**  \n",
        "   - Stops training if validation loss does not improve for 10 epochs.  \n",
        "   - `min_delta=0.001` means improvement smaller than this is ignored.  \n",
        "   - `restore_best_weights=True` keeps the weights from the best epoch.  \n",
        "\n",
        "- **Wrap with `KerasRegressor`**  \n",
        "   - Allows sklearn-style training (`fit`, `predict`).  \n",
        "   - Trains for 50 epochs with batch size = 32.  \n",
        "\n",
        "- Fits the model on the training dataset (`X_train`, `y_train`).  \n",
        "- Predicts values for the test dataset (`X_test`).  \n",
        "- Evaluates performance with two metrics:  \n",
        "  - **RMSE** (Root Mean Squared Error): measures prediction error magnitude,  \n",
        "  - **R² (Coefficient of Determination):** proportion of variance explained.  \n",
        "\n",
        "Reference reading:https://machinelearningmastery.com/understanding-simple-recurrent-neural-networks-in-keras/\n"
      ],
      "metadata": {
        "id": "zWhkgVOladAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_model():\n",
        "  model = Sequential() #initializing sequential model, layers can be added sequentially with model.add\n",
        "  model.add(SimpleRNN(20, input_shape=(4,1),activation='relu')) #simple recurrent layer, 10 neurons & process 50x1 sequences\n",
        "  model.add(Dense(10, activation='relu',kernel_regularizer=regularizers.l2(l2=0.001)))\n",
        "  model.add(Dense(10, activation='relu',kernel_regularizer=regularizers.l2(l2=0.001)))\n",
        "  model.add(Dense(10, activation='relu',kernel_regularizer=regularizers.l2(l2=0.001)))\n",
        "  model.add(Dense(1,activation='linear')) #linear output because this is a regression problem\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='mse', optimizer= optimizer, metrics=['mse','mae'])\n",
        "  return model\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience = 10, min_delta = 0.001, restore_best_weights = True)\n",
        "rnn = KerasRegressor(model = rnn_model, batch_size = 32, epochs = 100, callbacks = [early_stopping],verbose = 1)\n",
        "\n",
        "modelrnn = rnn\n",
        "modelrnn.fit(X_train, y_train,validation_data=(X_test, y_test))\n",
        "history = modelrnn.history_\n",
        "y_predictrnn = modelrnn.predict(X_test)\n",
        "print('RMSErnn:', np.sqrt(metrics.mean_squared_error(y_test,y_predictrnn)))\n",
        "print('R-Squaredrnn: %.3f' % (metrics.r2_score(y_test,y_predictrnn)))"
      ],
      "metadata": {
        "id": "DM6UcjGN36Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5. Visualize Training Performance**\n",
        "\n",
        "After training the RNN, we want to inspect how the error evolved over epochs.  \n",
        "- Extracts the **training and validation MSE history** from the `history` object.  \n",
        "   - Uses `.get()` so it works whether the metric key is stored as `'mse'` or `'mean_squared_error'` (naming can differ by TensorFlow/Keras versions).  \n",
        "   - Same for validation metrics (`'val_mse'` or `'val_mean_squared_error'`).  \n",
        "- Plots the training vs. validation errors across epochs.  \n",
        "- Labels the y-axis as **MSE**, even though we are plotting raw MSE values.  \n",
        "\n",
        "Why this matters?\n",
        "- If **training error decreases but validation error increases**, the model may be **overfitting**.  \n",
        "- If both errors are flat and high, the model is **underfitting**.  \n",
        "- Ideally, both training and validation errors decrease and stabilize at similar values.  \n",
        "- Reference reading:https://www.geeksforgeeks.org/deep-learning/training-and-validation-loss-in-deep-learning/"
      ],
      "metadata": {
        "id": "hUo88-clbLzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you didn’t add custom rmse, use sqrt of mse\n",
        "train_mse = history.get('mse', history.get('mean_squared_error'))\n",
        "val_mse   = history.get('val_mse', history.get('val_mean_squared_error'))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_mse, label='Train MSE')\n",
        "plt.plot(val_mse, label='Test MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE per Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_sCs-iP3Dj3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6. Train and Evaluate Random Forest Model**\n",
        "\n",
        "We now apply a **Random Forest Regressor** to predict Tcns (or another target variable) using the weather predictors.  \n",
        "\n",
        "\n",
        "- Initializes a `RandomForestRegressor` with:\n",
        "  - `n_estimators=50` → number of decision trees,  \n",
        "  - `max_depth=10` → maximum depth of each tree (prevents overfitting),  \n",
        "  - `random_state=42` → reproducibility,  \n",
        "  - `n_jobs=-1` → use all available CPU cores.  \n",
        "- Fits the model on the training dataset (`X_train`, `y_train`).  \n",
        "- Predicts values for the test dataset (`X_test`).  \n",
        "- Evaluates performance with two metrics:  \n",
        "  - **RMSE** (Root Mean Squared Error): measures prediction error magnitude,  \n",
        "  - **R² (Coefficient of Determination):** proportion of variance explained.  "
      ],
      "metadata": {
        "id": "snjmRNIrcgcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfmodel = RandomForestRegressor(n_estimators=50,max_depth=10,random_state=42, n_jobs=-1)\n",
        "rfmodel.fit(X_train, y_train)\n",
        "y_predictrf = rfmodel.predict(X_test)\n",
        "print('RMSErf:', np.sqrt(metrics.mean_squared_error(y_test,y_predictrf)))\n",
        "print('R-Squaredrf: %.3f' % (metrics.r2_score(y_test,y_predictrf)))"
      ],
      "metadata": {
        "id": "sLagoUwl4-Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7. Cross-Validation with RMSE (Random Forest & RNN)**\n",
        "\n",
        "To make sure our models are not just fitting by chance, we perform **k-fold cross-validation** with **RMSE** as the evaluation metric.  \n",
        "\n",
        "- Defines a helper function `modelmetrics_rmse(model, X, Y)`:\n",
        "  - Uses `RepeatedKFold` (3 splits × 6 repeats = 18 folds total).  \n",
        "  - Runs `cross_val_score` with **negative RMSE** scoring (sklearn convention).  \n",
        "  - Returns the array of RMSE scores (converted back to positive).  \n",
        "\n",
        "Cross-validation helps estimate the model’s **generalization performance** and highlights variability across folds (via standard deviation).  \n"
      ],
      "metadata": {
        "id": "mj3WLz5KdBgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modelmetrics_rmse(model, X, Y):\n",
        "    cv = RepeatedKFold(n_splits=3, n_repeats=6, random_state=1)\n",
        "    scores = cross_val_score(\n",
        "        model, X, Y,\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        cv=cv,\n",
        "        n_jobs=-1,\n",
        "        error_score='raise'\n",
        "    )\n",
        "    return -scores  # returns an array of RMSE values\n",
        "\n",
        "\n",
        "rmse_scores_rf = modelmetrics_rmse(rfmodel, X, y)\n",
        "print(\"RF Mean RMSE:\", rmse_scores_rf.mean())\n",
        "print(\"RF Std RMSE:\", rmse_scores_rf.std())\n",
        "\n",
        "rmse_scores_rnn= modelmetrics_rmse(modelrnn, X, y)\n",
        "print(\"RNN Mean RMSE:\", rmse_scores_rnn.mean())\n",
        "print(\"RNN Std RMSE:\", rmse_scores_rnn.std())"
      ],
      "metadata": {
        "id": "TQGrvMRs47le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8. Visualize Model Performance (Observed vs. Predicted)**\n",
        "\n",
        "We now compare predictions from the **RNN** and **Random Forest (RF)** models against observed values using scatter plots.  \n",
        "\n",
        "**What this does:**\n",
        "- Creates a figure with **two subplots** (side by side).  \n",
        "    - Left subplot (RNN)\n",
        "    - Right subplot (RF)\n",
        "\n",
        "- Points close to the 1:1 line indicate good performance.\n",
        "\n",
        "\n",
        "Observed vs. predicted plots provide a **quick visual diagnostic** of model accuracy and bias.   \n"
      ],
      "metadata": {
        "id": "FRXddgQBeNYv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKQ_koOQ6RdJ"
      },
      "outputs": [],
      "source": [
        "#subplots returns a Figure and an Axes object\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
        "\n",
        "# --- RNN subplot ---\n",
        "ax[0].scatter(y_test, y_predictrnn,\n",
        "              edgecolor='black', facecolor='none',\n",
        "              label=f'RNN, $R^2$ = {metrics.r2_score(y_test, y_predictrnn):.3f}')\n",
        "ax[0].plot([15, 35], [15, 35], 'k--', lw=0.5)\n",
        "ax[0].set_title(\"RNN\")\n",
        "ax[0].set_xlabel('Observed ($^\\circ$C)')\n",
        "ax[0].set_ylabel('Predicted ($^\\circ$C)')\n",
        "ax[0].set_xlim(15, 35); ax[0].set_ylim(15, 35) #Sets consistent axis ranges (15–35 °C) for fair comparison.\n",
        "ax[0].legend()\n",
        "\n",
        "# --- RF subplot ---\n",
        "ax[1].scatter(y_test, y_predictrf,\n",
        "              color='blue', alpha=0.5,\n",
        "              label=f'RF, $R^2$ = {metrics.r2_score(y_test, y_predictrf):.3f}')\n",
        "ax[1].plot([15, 35], [15, 35], 'k--', lw=0.5)\n",
        "ax[1].set_title(\"Random Forest\")\n",
        "ax[1].set_xlabel('Observed ($^\\circ$C)')\n",
        "ax[1].set_ylabel('Predicted ($^\\circ$C)')\n",
        "ax[1].set_xlim(15, 35); ax[1].set_ylim(15, 35) #Sets consistent axis ranges (15–35 °C) for fair comparison.\n",
        "ax[1].legend()\n",
        "\n",
        "plt.tight_layout() #Uses `plt.tight_layout()` to avoid overlap.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Other Reference Readings:**\n",
        "1. Hyperparameter tuning: https://thinkingneuron.com/how-to-use-artificial-neural-networks-for-classification-in-python/\n",
        "2. RNN: https://towardsdatascience.com/rnn-recurrent-neural-networks-how-to-successfully-model-sequential-data-in-python-5a0b9e494f92\n",
        "3. rnn sample code: https://www.datatechnotes.com/2018/12/rnn-example-with-keras-simplernn-in.html\n",
        "4. Random Forest:https://www.geeksforgeeks.org/machine-learning/random-forest-algorithm-in-machine-learning/\n",
        "5. Why kfold CV: https://towardsdatascience.com/the-importance-of-k-fold-cross-validation-for-model-prediction-in-machine-learning-4709d3fed2ef\n",
        "6. Real-time irrigation scheduling of maize using Degrees Above Non-Stressed (DANS) index: https://www.sciencedirect.com/science/article/pii/S0378377422005042\n",
        "7. Weather data-centric prediction of maize non-stressed canopy temperature:https://link.springer.com/article/10.1007/s00271-023-00863-w"
      ],
      "metadata": {
        "id": "KvOJcXfVf6Gc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}